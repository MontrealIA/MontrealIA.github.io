{"pages":[{"title":"Montr√©al Artificial Intelligence","text":"Montr√©al.AI Web ‚Äî The Dawn of Artificial IntelligenceArtificial Intelligence for the Web : Converting AI Research into Commercial Successes. At the forefront of AI, deploying superhuman agents that can learn from experience in the browser unlocks new powerful possibilities to apply AI in ways we never thought of! E.g., on a mobile device, the autonomous agent can leverage sensor data (i.e.: gyroscope or accelerometer) and take actions. True understanding comes from agents that learn by ‚Äúseeing‚Äù how they affect the world. All data stays on the client, making AI agents in the browser useful for privacy preserving applications. ‚Äú Artificial Intelligence is about recognising patterns, Artificial Life is about creating patterns. ‚Äú ‚Äî Mizuki Oka et al, #alife2018 A Proof of Concept : Getting Alexa to Respond to Sign LanguageUsing TensorFlow to make an Amazon Echo respond to sign language, by M. A. Singh : Blog Post by by M. A. Singh Code for the Proof of Concept on GitHub Advanced and Impactful Open-Source TechnologiesBringing contributions by scholars recognized as the foremost authorities in their fields, Montr√©al Artificial Intelligence is ahead of trends that will profoundly influence the future of Humanity. Cutting edge open-source technologies proudly used : 1. TensorFlow.jsTraining and Deploying ML Models in the Browser TensorFlow.js uses flexible and intuitive APIs to build and train models from scratch using a low-level JavaScript linear algebra library or a high-level layers API. The TensorFlow.js model converters allows running pre-existing TensorFlow models right in the browser or under Node.js. Pre-existing ML models can be retrained using sensor data connected to the browser, or other client-side data. Three development workflows : Importing an existing, pre-trained model for inference ; Re-training an imported model quickly (transfer learning) with only a small amount of data ; and Authoring (define, train, and run) models directly in the browser. TensorFlow.js AI agents can be trained using reinforcement learning, neuroevolution, or other machine learning methods. There‚Äôs no need to install anything. Just open a webpage, and your AI Agent is ready to run. References : TensorFlow.js TensorFlow dev summit Official TensorFlow.js Launch Introducing TensorFlow.js by Josh Gordon and Sara Robinson Deep Learning in JS - Ashi Krishnan - JSConf EU 2018 TensorFlow.js Gallery 2. Reinforcement LearningGoing Beyond Input-Output Pattern Recognition In the past few years deep reinforcement learning started achieving state-of-the-art results. ‚Äú Reinforcement learning (RL) is the subfield of machine learning concerned with decision making and motor control. It studies how an agent can learn how to achieve goals in a complex, uncertain environment. ‚Äú ‚Äî OpenAI At the bleeding edge of AI, autonomous agents can learn from experience, simulate worlds and orchestrate meta-solutions. Here‚Äôs an inspiring example of a high-quality implementation of a reinforcement learning algorithm : Powerful and useful application domains : Dialogue, Healthcare, Management, Robotics, Smart Grid, Supply Chains, etc. ‚Äú Self-Play is Automated Knowledge Creation. ‚Äú ‚Äî Carlos E. Perez References : OpenAI Gym by OpenAI OpenAI Baselines by OpenAI AlphaGo Zero: Learning from scratch by DeepMind A Visual Guide to Evolution Strategies by David Ha OpenAI Five by OpenAI 3. TensorFlow HubReusing Machine Learning Modules TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning. Transfer learning can: Train a model with a smaller dataset ; Improve generalization: and Speed up training. ‚Äú I think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from. ‚Äú ‚Äî Demis Hassabis TensorFlow Hub Introducing TensorFlow Hub by Josh Gordon Transform your Web Site with an AI AgentFully-fledged AI systems can achieve serious revenue! Montr√©al Artificial Intelligence helps to transform Web sites for the age of artificial intelligence by developing machine learning agents in the browser that achieves goal-oriented behavior. Demos : Solving the cart-pole control problem in the browser using the policy-gradient method Live demo : https://storage.googleapis.com/tfjs-examples/cart-pole/dist/index.html Code : https://github.com/tensorflow/tfjs-examples/tree/master/cart-pole Predicting balls and strikes using TensorFlow.js Blog : https://medium.com/tensorflow/predicting-balls-and-strikes-using-tensorflow-js-2acf1d7a447c Animation with CPPNs and TensorFlow.js, an @observablehq notebook by Emily Reif @observablehq notebook by Emily Reif : https://beta.observablehq.com/@emilyreif/animation-with-cppns Move Mirror: An AI Experiment with Pose Estimation in the Browser using TensorFlow.js By Jane Friedhoff and Irene Alvarado : https://medium.com/tensorflow/move-mirror-an-ai-experiment-with-pose-estimation-in-the-browser-using-tensorflow-js-2f7b769f9b23 L1: Tensor Studio ‚Äî An in-browser live-programming environment by Milan Lajto≈° Live demo : https://mlajtos.github.io/L1/latest/ Github : https://github.com/mlajtos/L1 References : Unity ML-Agents Toolkit by Unity A Brief Survey of Deep Reinforcement Learning Arulkumaran et al. ‚Äú Nothing is more powerful than an idea whose time has come. ‚Äú ‚Äî Victor Hugo MontreÃÅal.AI is offering a new world age of impactful technical prowesses on an unprecedented scale. To order your AI Agent :‚úâÔ∏è Email Us : info@montreal.ai #AI #AIFirst #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealIA.github.io/web-ai/index.html"},{"title":"MONTR√âAL.IA | Intelligence Artificielle Montr√©al","text":"Le Cabinet-Conseil de Montr√©al.IAUne intelligence artificielle tangible et d√©cisive Consid√©rant que les meilleurs talents en IA sont rares, Montr√©al.IA offre un service de consultation. ‚Äú Nous voulons voir une interop√©rabilit√© matricielle, des opportunit√©s d‚Äôapprentissage, ainsi que le d√©veloppement de ‚ÄòChief AI Officers‚Äò poss√©dant les comp√©tences n√©cessaires pour orchestrer des avanc√©es d√©cisives et une croissance √©conomique tangible pour les Fortune 500, les gouvernements et les partenaires institutionnels.‚Äú Montr√©al.IA : Les meilleurs conseillers en IA √† Montr√©alMontr√©al.IA rel√®ve les d√©fis les plus difficiles. R√©unissant des contributions de chercheurs et de praticiens reconnus comme √©tant les principales autorit√©s dans leur domaine, le Cabinet-Conseil de Montr√©al.IA offre une intelligence artificielle pratique et tr√®s puissante. L‚ÄôAtelier Montr√©al.IA: Des algorithmes IA sur mesureL‚ÄôAtelier Montr√©al.IA cr√©e et d√©ploie des mod√®les d‚ÄôIA haut de gamme et des syst√®mes d‚ÄôIA √† part enti√®re. ‚ÄúUne perc√©e en apprentissage automatique vaudrait 10 fois Microsoft.‚Äú ‚Äî Bill Gates Montr√©al.IA A√©rospatialUne nouvelle √®re globale de prouesses techniques Montr√©al.IA A√©rospatial s‚Äôappuie sur l‚Äôing√©nierie a√©rospatiale, l‚Äôintelligence artificielle appliqu√©e et la recherche en astrophysique pour optimiser les vols spatiaux, l‚Äôefficacit√© des satellites et l‚Äôexploration spatiale. ‚ÄúReconnaissant que Montr√©al est un p√¥le mondial de l‚Äôindustrie a√©rospatiale et un chef de file en intelligence artificielle, nous avons constitu√© Montr√©al.IA A√©rospatial.‚Äú ‚Äî Vincent Boucher, B. Sc. Physique, M.A. Analyse des politiques gouvernementales et M. Sc. G√©nie a√©rospatial (technologie spatiale), pr√©sident-fondateur de Montr√©al.IA Blockchain et intelligence artificielle chez Montr√©al.IA‚Äú‚Ä¶il n‚Äôy a pas de discrimination entre les robots ou les humains dans l‚Äô√©cosyst√®me Ethereum‚Ä¶‚Äú ‚Äî Fondation Ethereum AI + Ethereum = vie artificielle D√©ploiement d‚Äôefficaces agents IA sur Blockchain; D√©veloppement de multi-agents DAO; Engendrement de la vie artificielle sur Blockchain. Montr√©al.IA DAO:Plateforme agnostique pour le d√©veloppement d‚Äôorganisations autonomes d√©centralis√©es (entreprises, organisations gouvernementales, instituts, ‚Ä¶) + Une bo√Æte √† outils pour y d√©ployer l‚ÄôIA. Chief AI Officers : Formation en IA pour les cadresUne formation s‚Äôappuyant sur plus d‚Äôun million de dollars (1 000 000 $) en recherche sur l‚ÄôIA ‚ÄòChief AI Officers‚Äô : Une formation en IA pour les cadres qui maximise les principes fondamentaux de l‚Äôintelligence artificielle √† un niveau sup√©rieur. Elle incite les d√©cideurs √† les mettre en pratique de mani√®re strat√©gique dans les entreprises, les gouvernements et les institutions avec une ing√©nierie de pr√©cision. ‚ÄúDans un moment de bouleversement technologique, le leadership compte.‚Äú ‚Äî Andrew Ng Le succ√®s consiste √† fa√ßonner activement le jeu qui compte pour vous. Cette formation professionnelle est exclusive et a √©t√© con√ßue pour atteindre une compr√©hension pointue des strat√©gies en intelligence artificielle transformatrice, donnant ainsi de nouvelles perspectives aux organisations √©tatiques, nationales et internationales. Profil des participants‚ÄúNous voulons voir une interop√©rabilit√© matricielle plus √©tendue, des opportunit√©s d‚Äôapprentissage individuel et permanent, ainsi que le d√©veloppement de Chief AI Officers poss√©dant les connaissances, les comp√©tences et les outils n√©cessaires pour orchestrer des avanc√©es d√©cisives et une croissance √©conomique tangible pour les Fortune 500, les gouvernements et les partenaires institutionnels et ce, en harmonie avec le ‚ÄòMontr√©al AI-First Conglomerate Overarching Program‚Äô.‚Äú ‚Äî Vincent Boucher, Pr√©sident et fondateur de Montr√©al.IA, B. Sc. Physique, M.A. Analyse des politiques gouvernementales et M. Sc. G√©nie a√©rospatial (technologie spatiale) ‚ÄòChief AI Officers‚Äô : Formation en IA pour les cadres a √©t√© √©labor√©e pour des: Membres de conseil d‚Äôadministration; Capitaines d‚Äôindustrie; Chanceliers; Directeurs g√©n√©raux; Commandants; Excellences; Titulaires de chaires; Cadres √† haut potentiel; Entrepreneurs iconiques en technologie; Intellectuels; Directeurs marketing; Influenceurs; Philanthropes; Pr√©sidents; Boursiers; Entrepreneurs et financiers prosp√®res; Fondateurs visionnaires ‚Ä¶ qui souhaitent exalter de mani√®re strat√©gique le pouvoir de l‚Äôintelligence artificielle √† une √©chelle v√©ritablement mondiale. Rejoignez-nous ‚Äî Une opportunit√© unique dans une vie MONTR√âAL.IA s‚Äôefforce de r√©unir les meilleurs experts, les capitaines d‚Äôindustries et les dirigeants chevronn√©s en intelligence artificielle afin de constituer une √©quipe de consultants pr√©√©minente et reconnue. Pour postuler afin de faire partie de notre groupe de consultants exceptionnels: rh@montreal.ai R√©f√©rences‚ÄúL‚Äôann√©e derni√®re, le co√ªt d‚Äôun expert en apprentissage profond ¬´ deep learning ¬ª de classe mondiale √©tait √† peu pr√®s le m√™me que celui d‚Äôun joueur quart-arri√®re de la NFL. Le co√ªt de ce talent est assez remarquable.‚Äú ‚Äî Peter Lee, Microsoft Million-dollar babies ‚Äî The Economist The Battle for Top AI Talent Only Gets Tougher From Here ‚Äî Wired The Tech Oligopoly ‚Äî Part 1 | The New Kingmakers ‚Äî Arif Khan Oracle recently offered an artificial intelligent expert as much as $6 million in total pay as Silicon Valley‚Äôs talent war heats up ‚Äî The Economist A.I. Researchers Are Making More Than $1 Million, Even at a Nonprofit ‚Äî The New York Times ‚ÄúC‚Äôest le printemps pour l‚ÄôIA et nous anticipons un long √©t√©.‚Äú ‚Äî Bill Braun, CIO de Chevron ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #Chief AI Officers #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/cabinet-conseil/index.html"},{"title":"MONTR√âAL.IA | Intelligence Artificielle Montr√©al","text":"L‚ÄôAcad√©mie de Montr√©al.IAINTELLIGENCE ARTIFICIELLE 1011er survol de l‚ÄôIA de classe mondiale pour le grand publicLes billets se vendent rapidement ! CET √âV√âNEMENT SERA COMPLET.Englobant toutes les facettes de l‚ÄôIA, le Secr√©tariat g√©n√©ral de MONTR√âAL.IA pr√©sente, avec autorit√©: ‚ÄúIntelligence Artificielle 101 : Le premier survol de l‚ÄôIA de classe mondiale pour le grand public‚Äú. Intelligence Artificielle 101 | Date et heure: Mercredi, 11 mars 2020 19:00 ‚Äì 20:30 | Lieu: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8 L‚ÄôIA ouvre un monde de nouvelles possibilit√©s. Ce cours IA 101 explore les bases de l‚Äôintelligence artificielle dans le but de transmettre aux participant(e)s de puissants outils d‚ÄôIA pour apprendre, d√©ployer et faire √©voluer l‚ÄôIA. ‚Äú(AI) will rank among our greatest technological achievements, and everyone deserves to play a role in shaping it.‚Äú ‚Äî Fei-Fei Li Un cours de 75 minutes bien con√ßu et pratiquePUISSANT ET UTILE. Ce cours est con√ßu pour confier aux participant(e)s l‚Äô√©tat d‚Äôesprit, les comp√©tences et les outils n√©cessaires pour percevoir l‚Äôintelligence artificielle d‚Äôun point de vue novateur et stimulant. Il met en lumi√®re : Des d√©couvertes et des connaissances scientifiques de pointe; Les meilleurs codes et impl√©mentations ‚Äúopen source‚Äù ; L‚Äôimpulsion qui anime l‚Äôintelligence artificielle d‚Äôaujourd‚Äôhui. Aper√ßu du programme (‚ÄúInstituer une compr√©hension percutante de l‚ÄôIA‚Äù) ‚ùñ Discours d‚Äôintroduction S√©ance 0 ¬∑ Pour commencer Dans le nuage Sur une machine locale S√©ance 1 ¬∑ Apprentissage profond R√©seaux de neurones R√©seaux de neurones convolutifs (CNN) R√©seaux de neurones r√©currents (RNN) Apprentissage profond non supervis√© (apprentissage auto-supervis√©, r√©seaux g√©n√©ratifs par antagonisme et auto-encodeurs variationnels) S√©ance 2 ¬∑ Agents autonomes Strat√©gies d‚Äô√©volution Apprentissage par renforcement en profondeur Apprentissage contre soi (Self Play) : Un saut quantique M√©ta-apprentissage profond S√©ance 3 ¬∑ Environnements OpenAI Gym DeepMind Lab Unity ML-Agents ‚ùñ Allocution sp√©ciale Le conf√©rencierConf√©rencier: Vincent Boucher, pr√©sident-fondateur de MONTR√âAL.AI. En 1996, Vincent Boucher a compl√©t√© un B. Sc. Physique th√©orique en 1 (un) an, suivi d‚Äôune ma√Ætrise en analyse des politiques gouvernementales (1998) et d‚Äôune ma√Ætrise en g√©nie a√©rospatial (technologie spatiale) (2000). De 2000 √† 2002, il a oeuvr√© √† titre de consultant pour l‚ÄôAgence spatiale canadienne. En 2003, Vincent Boucher a fond√© MONTREAL.AI | Montr√©al Artificial Intelligence. Une histoire l√©gendaire | Comment tout a commenc√© ‚Äî Apprenez la source d‚Äôun h√©ritage exceptionnel : Vincent Boucher | ‚Ä¶ un cerveau de l‚Äôa√©rospatial! ‚Äî Le journal de Montreal √âtoiles filantes | Vincent Boucher ‚Äî Le bulletin des employ√©s de l‚ÄôAgence spatiale canadienne Vincent Boucher | Un (jeune) homme d‚Äôexception ‚Äî Nathalie Petrowski, La Presse Billets et r√©servation de groupe var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '80189080699', iframeContainerId: 'eventbrite-widget-container-80189080699', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); Billets: https://intelligenceartificielle101.eventbrite.ca R√©servation de groupe: secretariat@montreal.ai Date et heure: Mercredi, 11 mars 2020 | 19:00 ‚Äì 20:30 HAE Langue: La pr√©sentation sera en fran√ßais. Le mat√©riel de r√©f√©rence sera dans sa langue originale. Lieu: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. Aide-m√©moire VIP IA 101 pour toutes et pour tousDans le but de transmettre √† tous les √™tres sensibles de puissants outils d‚ÄôIA pour apprendre, d√©ployer et faire √©voluer l‚ÄôIA, afin d‚Äôaccro√Ætre la prosp√©rit√©, de r√©gler les probl√®mes plan√©taires et d‚Äôinspirer celles et ceux qui, avec l‚ÄôIA, fa√ßonneront le 21√®me si√®cle, Montr√©al.IA pr√©sente l‚ÄôAide-m√©moire VIP IA 101. Aide-m√©moire VIP IA 101 pour toutes et pour toushttp://www.montreal.ai/ai4all.pdf Une liste de codes et impl√©mentations en ‚Äúopen source‚Äù confectionn√©e √† titre gracieux:Montr√©al.IA est la plus grande communaut√© IA au Canada. Rejoignez-nous et apprenez tout de l‚ÄôIA! https://www.facebook.com/groups/MontrealAI/ ! *Cette section est pr√©sent√©e dans sa langue originale anglaise. 0. Getting StartedAI opens up a world of new possibilities. Today‚Äôs artificial intelligence is powerful, useful and accessible to all. Tinker with Neural Networks : Neural Network Playground ‚Äî TensorFlow In the Cloud Free GPU compute via Colab. Colab: An easy way to learn and use TensorFlow ‚Äî TensorFlow Six easy ways to run your Jupyter Notebook in the cloud ‚Äî Data School Practice Immediately ‚Äî Goku Mohandas On a Local Machine Install Anaconda and Launch ‚ÄòAnaconda Navigator‚Äô. Update Jupyterlab and Launch the Application. Under Notebook, Click on ‚ÄòPython 3‚Äô. In the Browser TensorFlow.js: a library for developing and training ML models in JavaScript. TensorFlow dev summit Official TensorFlow.js Launch Introducing TensorFlow.js: Machine Learning in Javascript ‚Äî Josh Gordon, Sara Robinson TensorFlow.js: Machine Learning for the Web and Beyond ‚Äî Daniel Smilkov, Nikhil Thorat, Yannick Assogba, Ann Yuan, Nick Kreeger, Ping Yu, Kangyi Zhang, Shanqing Cai, Eric Nielsen, David Soergel, Stan Bileschi, Michael Terry, Charles Nicholson, Sandeep N. Gupta, Sarah Sirajuddin, D. Sculley, Rajat Monga, Greg Corrado, Fernanda B. Viegas, Martin Wattenberg Datasets Making it easier to discover datasets. Preliminary Readings ‚ÄúWhen you first study a field, it seems like you have to memorize a zillion things. You don‚Äôt. What you need is to identify the 3-5 core principles that govern the field. The million things you thought you had to memorize are various combinations of the core principles.‚Äú ‚Äî J. Reed Deep Learning ‚Äî Yann LeCun, Yoshua Bengio, Geoffrey Hinton Papers With Code! | Over 950+ ML tasks, 500+ evaluation tables (including state of the art results) and 8500+ papers with code! ‚Äî Atlas ML Learn X in Y minutes (Where X=python3) ‚Äî Louie Dinh 6.S191: Introduction to Deep Learning | MIT‚Äôs official introductory course on deep learning methods and applications. ‚Äî Alexander Amini and Ava Soleimany Practical Deep Learning for Coders 2019 ‚Äî Jeremy Howard Foundations Built for a General Theory of Neural Networks ‚Äî Kevin Hartnett The Matrix Calculus You Need For Deep Learning ‚Äî Terence Parr, Jeremy Howard Introduction to the math of backprop ‚Äî Deb Panigrahi Introduction to Applied Linear Algebra ‚Äì Vectors, Matrices, and Least Squares ‚Äî Stephen Boyd and Lieven Vandenberghe, Cambridge University Press What are the limits of deep learning? ‚Äî M. Mitchell Waldrop ‚ÄúA birds-eye view of optimization algorithms‚Äù ‚Äî Fabian Pedregosa Using Nucleus and TensorFlow for DNA Sequencing Error Correction ‚Äî Gunjan Baid, Helen Li and Pi-Chuan Chang Dive into Deep Learning ‚Äî Aston Zhang, Zack C. Lipton, Mu Li, Alex J. Smola How to visualize decision trees ‚Äî Terence Parr, Prince Grover Machine Learning for Visualization ‚Äî Ian Johnson Seeing Theory: A visual introduction to probability and statistics. ‚Äî Daniel Kunin et al. explained.ai | Deep explanations of machine learning ‚Äî Terence Parr What is torch.nn really? ‚Äî Jeremy Howard Scipy Lecture Notes ‚Äî Scipy Deep Learning and Robotics ‚Äî Pieter Abbeel Natasha Jaques: ‚ÄúRecent advances in AI and machine learning‚Äù | Starsconf 2018 ‚Äî Natasha Jaques | Starsconf 2018 CS 188 | Introduction to Artificial Intelligence ‚Äî Pieter Abbeel, Dan Klein A Concise Handbook of TensorFlow ‚Äî Xihan Li The WIRED Guide to artificial intelligence ‚Äî WIRED How to teach yourself hard things ‚Äî Julia Evans UFLDL (Unsupervised Feature Learning and Deep Learning) Tutorial ‚Äî Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen Interview with The Youngest Kaggle Grandmaster: Mikel Bober-Irizar (anokas) ‚Äî Sanyam Bhutani, Hacker Noon Cutting-Edge Face Recognition is Complicated. These Spreadsheets Make it Easier. ‚Äî Dave Smith A radical new neural network design could overcome big challenges in AI ‚Äî Karen Hao Remarkable problem-solving ability of unicellular amoeboid organism and its mechanism ‚Äî Liping Zhu, Song-Ju Kim, Masahiko Hara, Masashi Aono Competitive Programmer‚Äôs Handbook ‚Äî Antti Laaksonen Machine Learning from scratch! ‚Äî Quan Tran Rules of Machine Learning: Best Practices for ML Engineering ‚Äî Martin Zinkevich A Neural Network in 11 lines of Python ‚Äî iamtrask ‚Äú1. Multiply things together 2. Add them up 3. Replaces negatives with zeros 4. Return to step 1, a hundred times.‚Äú ‚Äî Jeremy Howard How to build your own Neural Network from scratch in Python ‚Äî James Loy Deep Gaussian Processes ‚Äî Neil D. Lawrence Magic Sketchpad ‚Äî Monica Dinculescu AI Transformation Playbook ‚Äî Andrew Ng Understand TensorFlow by mimicking its API from scratch ‚Äî Dominic Elm Bias-Variance Decomposition ‚Äî Sebastian Raschka SpaceSheet: Interactive Latent Space Exploration through a Spreadsheet Interface Paper | Demo | Tool ‚Äî Bryan Loh, Tom White On intelligence: its creation and understanding ‚Äî Surya Ganguli NeurIPS 2018 Videos ‚Äî Thirty-second Conference on Neural Information Processing Systems Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks ‚Äî Adam Geitgey The Neural Aesthetic ‚Äî Gene Kogan MONet: Unsupervised Scene Decomposition and Representation ‚Äî Christopher P. Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina Higgins, Matt Botvinick, Alexander Lerchner Popular Machine Learning Algorithms Explained Project Jupyter | GitHub ‚Äî Oleksii Trekhleb Introduction to Artificial Intelligence, ULi√®ge, Fall 2018. ‚Äî Gilles Louppe Deep Learning cheatsheets for Stanford‚Äôs CS 230 ‚Äî Afshine Amidi, Shervine Amidi TensorFlow Blog ‚Äî TensorFlow Machine Learning From Scratch ‚Äî Erik Linder-Nor√©n A Beginner‚Äôs Guide to the Mathematics of Neural Networks ‚Äî A.C.C. Coolen An embedding is a mapping from discrete objects, such as words, to vectors of real numbers. 1. Deep LearningDeep learning allows computational models that are composed of multiple processing layers to learn REPRESENTATIONS of (raw) data with multiple levels of abstraction. At a high-level, neural networks are either encoders, decoders, or a combination of both. ‚ÄúDL is essentially a new style of programming‚Äì‚Äùdifferentiable programming‚Äù‚Äìand the field is trying to work out the reusable constructs in this style. We have some: convolution, pooling, LSTM, GAN, VAE, memory units, routing units, etc.‚Äú ‚Äî Thomas G. Dietterich 1.1 Neural Networks ‚ÄúNeural networks‚Äù are a sad misnomer. They‚Äôre neither neural nor even networks. They‚Äôre chains of differentiable, parameterized geometric functions, trained with gradient descent (with gradients obtained via the chain rule). A small set of highschool-level ideas put together.‚Äú ‚Äî Fran√ßois Chollet AI Playbook ‚Äî Andreessen Horowitz Clear Explanations of Machine Learning ‚Äî Distill Deep Learning Book ‚Äî Ian Goodfellow, Yoshua Bengio, Aaron Courville Neural Networks and Deep Learning ‚Äî Michael Nielsen Deep Learning ‚Äî Vincent Vanhoucke | Google A Complete Implementation of a Toy Neural Network ‚Äî Stanford CS class CS231n Neural networks: training with backpropagation ‚Äî Jeremy Jordan Introduction to Machine Learning for Coders ‚Äî Jeremy Howard Machine Learning Yearning ‚Äî Andrew Ng Effective TensorFlow for Non-Experts ‚Äî Google Developers Neural Network as Ordinary Differential Equations ‚Äî Kevin Gibson A curated collection of inspirational AI-powered JavaScript apps ‚Äî Elle Haproff, Asim Hussain, Osama Jandali Pytorch Implementation of Neural Processes ‚Äî Chris Ormandy A Few Unusual Autoencoders ‚Äî Colin Raffel Science of AI | How AI Training Scales ‚Äî OpenAI Pytorch implementation of JointVAE, a framework for disentangling continuous and discrete factors of variation ‚Äî Schlumberger Software Technology A New TensorFlow Hub Web Experience ‚Äî Andr√© Susano Pinto, Clemens Mewald Approximate Fisher Information Matrix to Characterise the Training of Deep Neural Networks ‚Äî Zhibin Liao, Tom Drummond, Ian Reid, Gustavo Carneiro Deep Learning on Graphs: A Survey ‚Äî Ziwei Zhang, Peng Cui, Wenwu Zhu TF Jam ‚Äî Shooting Hoops with Machine Learning ‚Äî Abe Haskins Building Web App for Computer Vision Model &amp; Deploying to Production in 10 Minutes*: A Detailed Guide ‚Äî Pankaj Mathur Measuring the Effects of Data Parallelism on Neural Network Training ‚Äî Christopher J. Shallue, Jaehoon Lee, Joe Antognini, Jascha Sohl-Dickstein, Roy Frostig, George E. Dahl Photo Wake-Up: 3D Character Animation from a Single Photo Paper | Project Page ‚Äî Chung-Yi Weng, Brian Curless, Ira Kemelmacher-Shlizerman Relational inductive biases, deep learning, and graph networks ‚Äî Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu Avito Demand Prediction Challenge : Kaggle winner explains how to combine categorical, numerical, image and text features into a single NN that gets you into top 10 without stacking ‚Äî Little Boat fast.ai | Making neural nets uncool again Intro Machine Learning | Practical Deep Learning | Cutting Edge Deep Learning | Computational Linear Algebra ‚Äî Jeremy Howard, Rachel Thomas | Fast.AI 1.1.1 Universal Approximation TheoremThe universal approximation theorem states that a feed-forward network with a single hidden layer containing a finite number of neurons can solve any given problem to arbitrarily close accuracy as long as you add enough parameters. Neural Networks + Gradient Descent + GPU: Infinitely flexible function: Neural Networks (multiple hidden layers: Deep Learning) ; All-purpose parameter fitting: Backpropagation ; and Fast and scalable: GPU. When a choice must be made, just feed the (raw) data to a deep neural network (universal function approximator). 1.2 Convolution Neural NetworkIn images, local combinations of edges form motifs, motifs assemble into parts, and parts form objects. The deep convolutional network, inspired by Hubel and Wiesel‚Äôs seminal work on early visual cortex, uses hierarchical layers of tiled convolutional filters to mimic the effects of receptive fields, thereby exploiting the local spatial correlations present in images. A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters. ‚ÄúI admire the elegance of your method of computation; it must be nice to ride through these fields upon the horse of true mathematics while the like of us have to make our way laboriously on foot.‚Äú ‚Äî A. Einstein CNN Is All You Need ‚Äî Qiming Chen, Ren Wu Feature Visualization ‚Äî Chris Olah, Alexander Mordvintsev, Ludwig Schubert Explanatory Graphs for CNNs ‚Äî Quanshi Zhang, Xin Wang, Ruiming Cao, Ying Nian Wu, Feng Shi, Song-Chun Zhu Understanding Neural Networks Through Deep Visualization ‚Äî Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson MedicalTorch ‚Äî Christian S. Perone How to visualize convolutional features in 40 lines of code ‚Äî Fabio M. Graetz Deep Learning for Generic Object Detection: A Survey ‚Äî Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, Matti Pietik√§inen A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs ‚Äî Jack Lindsey, Samuel A. Ocko, Surya Ganguli, Stephane Deny The Building Blocks of Interpretability ‚Äî Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, Alexander Mordvintsev Detectron : State-of-the-art Object Detection ‚Äî Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and Piotr Doll\\‚Äô{a}r and Kaiming He YOLOv3: An Incremental Improvement | WebSite | YouTube ‚Äî Joseph Redmon, Ali Farhadi From Recognition to Cognition: Visual Commonsense Reasoning ‚Äî Rowan Zellers, Yonatan Bisk, Ali Farhadi, Yejin Choi AdVis.js : Exploring Fast Gradient Sign Method ‚Äî Jason Lin, Dilara Soylu Machine Learning for Artists | Demos Page | This is how convolution works ‚Äî Machine Learning for Artists Deep Painterly Harmonization | Notebook ‚Äî Sylvain Gugger A Deep Learning based magnifying glass ‚Äî Francesco Cardinale How Convolutional Neural Networks Work ‚Äî Brandon Rohrer TensorSpace: Neural network 3D visualization framework ‚ÄîTensorSpace 1.3 Recurrent Neural NetworksFor sequential inputs. Recurrent neural networks are networks with loops in them, allowing information to persist. RNNs process an input sequence one element at a time, maintaining in their hidden units a ‚Äòstate vector‚Äô that implicitly contains information about the history of all the past elements of the sequence. Long Short-Term Memory ‚Äî Sepp Hochreiter, J√ºrgen Schmidhuber Understanding LSTM Networks ‚Äî Christopher Olah Can Neural Networks Remember? ‚Äî Vishal Gupta Attention and Augmented RNN ‚Äî Olah &amp; Carter, 2016 Computer, respond to this email ‚Äî Post by Greg Corrado How do Mixture Density RNNs Predict the Future? ‚Äî Kai Olav Ellefsen, Charles Patrick Martin, Jim Torresen Reversible Recurrent Neural Networks ‚Äî Matthew MacKay, Paul Vicol, Jimmy Ba, Roger Grosse Recurrent Relational Networks Blog | arXiv | Code ‚Äî Rasmus Berg Palm, Ulrich Paquet, Ole Winther The Unreasonable Effectiveness of Recurrent Neural Networks ‚Äî Andrej Karpathy Massive Exploration of Neural Machine Translation Architectures arXiv | Docs | Code ‚Äî Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le A TensorFlow implementation of : ‚ÄúHybrid computing using a neural network with dynamic external memory‚Äù GitHub ‚Äî Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi≈Ñska, Sergio G√≥mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adri√† Puigdom√®nech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu &amp; Demis Hassabis ‚ÄúI feel like a significant percentage of Deep Learning breakthroughs ask the question ‚Äúhow can I reuse weights in multiple places?‚Äù‚Äì Recurrent (LSTM) layers reuse for multiple timesteps‚Äì Convolutional layers reuse in multiple locations.‚Äì Capsules reuse across orientation.‚Äú ‚Äî Trask 1.4 Capsules Dynamic Routing Between Capsules ‚Äî Sara Sabour, Nicholas Frosst, Geoffrey E Hinton Capsule Networks (CapsNets) ‚Äì Tutorial ‚Äî Aur√©lien G√©ron Understanding Hinton‚Äôs Capsule Networks. Part I: Intuition. ‚Äî Max Pechyonkin Capsules for Object Segmentation ‚Äî Rodney LaLonde, Ulas Bagci Brain Tumor Type Classification via Capsule Networks ‚Äî Parnian Afshar, Arash Mohammadi, Konstantinos N. Plataniotis A Tensorflow implementation of CapsNet ‚Äî Huadong Liao 1.5 Unsupervised LearningTrue intelligence will require independent learning strategies. Unsupervised learning is a paradigm for creating AI that learns without a particular task in mind: learning for the sake of learning. It captures some characteristics of the joint distribution of the observed random variables (learn the underlying structure). Self-supervised learning is derived form unsupervised learning where the data provides the supervision. 1.5.1 Generative Adversarial NetworkSimultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. $$\\min_{\\theta_g} \\max_{\\theta_d} [{\\rm IE_{x\\sim p_{data}(x)}} [log D_{\\theta_d}(x)] + {\\rm IE_{z\\sim p_z(z)}} [log(1 - D_{\\theta_d}(G_{\\theta_g}(z)))]]$$ ‚ÄúWhat I cannot create, I do not understand.‚Äú ‚Äî Richard Feynman This framework corresponds to a minimax two-player game. Generative Adversarial Nets ‚Äî Goodfellow et al. Generative Models ‚Äî OpenAI GAN Lab: Play with Generative Adversarial Networks (GANs) in your browser! ‚Äî Minsuk Kahng, Nikhil Thorat, Polo Chau, Fernanda Vi√©gas, Martin Wattenberg Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch) ‚Äî Dev Nag TensorFlow-GAN (TFGAN) ‚Äî TensorFlow Few-Shot Adversarial Learning of Realistic Neural Talking Head Models Wasserstein GAN GANSynth: Generate high-fidelity audio with GANs! SC-FEGAN: Face Editing Generative Adversarial Network CariGANs: Unpaired Photo-to-Caricature Translation GANpaint Paint with GAN units PyTorch pretrained BigGAN Neural scene representation and rendering ‚Äî S. M. Ali Eslami, Danilo J. Rezende, Frederic Besse, Fabio Viola, Ari S. Morcos, Marta Garnelo, Avraham Ruderman, Andrei A. Rusu, Ivo Danihelka, Karol Gregor, David P. Reichert, Lars Buesing, Theophane Weber, Oriol Vinyals, Dan Rosenbaum, Neil Rabinowitz, Helen King, Chloe Hillier, Matt Botvinick, Daan Wierstra, Koray Kavukcuoglu, Demis Hassabis Recycle-GAN: Unsupervised Video Retargeting Paper | Blog ‚Äî Aayush Bansal, Shugao Ma, Deva Ramanan, Yaser Sheikh On Self Modulation for Generative Adversarial Networks ‚Äî Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly Bayesian GAN arXiv | GitHub ‚Äî Yunus Saatchi, Andrew Gordon Wilson Adversarial Transfer Learning ‚Äî Garrett Wilson, Diane J. Cook Generating Memoji from Photos ‚Äî Pat Niemeyer GANPaint ‚Äî MIT-IBM Watson AI Lab The GAN Zoo ‚Äî Avinash Hindupur A collection of GANs TensorFlow | PyTorch StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks Paper | Code StyleGAN for art This Person Does Not Exist Which Person Is Real? This Resume Does Not Exist This Waifu Does Not Exist Encoder for Official TensorFlow Implementation How to recognize fake AI-generated images ‚Äî Kyle McDonald Demo of BigGAN in an official Colaboratory notebook (backed by a GPU) 1.5.2 Variational Auto-Encoders (VAEs)Variational Auto-Encoders (VAEs) are powerful models for learning low-dimensional representations. Debiasing Facial Detection Systems - Colab SpaceSheet: Interactive Latent Space Exploration with a Spreadsheet MusicVAE: Learning latent spaces for musical scores Slides: A Few Unusual Autoencoders Generative models in Tensorflow 2 Disentangled VAE‚Äôs (DeepMind 2016) ‚ÄúI think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from.‚Äú ‚Äî Demis Hassabis 2. Autonomous AgentsReinforcement learning (RL) studies how an agent can learn how to achieve goals in a complex, uncertain environment. An autonomous agent is any device that perceives its environment and takes actions that maximize its chance of success at some goal. At the bleeding edge of AI, autonomous agents can learn from experience, simulate worlds and orchestrate meta-solutions. Here‚Äôs an informal definition of the universal intelligence of agent `\\pi` $$\\Upsilon(\\pi) := \\sum\\limits_{\\mu \\in E} 2^{-K(\\mu)} V^{\\pi}_{\\mu}$$ ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äú ‚Äî Shane Legg 2.1 Evolution Strategies ‚ÄúEvolution is a slow learning algorithm that with the sufficient amount of compute produces a human brain.‚Äú ‚Äî Wojciech Zaremba Evolution and neural networks proved a potent combination in nature. Natural evolutionary strategy directly evolves the weights of a DNN and performs competitively with the best deep reinforcement learning algorithms. Neuroevolution enables capabilities that are typically unavailable to gradient-based approaches. A Visual Guide to Evolution Strategies ‚Äî David Ha Evolution Strategies as a Scalable Alternative to Reinforcement Learning ‚Äî OpenAI The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities ‚Äî Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee Altenberg, Julie Beaulieu, Peter J. Bentley, Samuel Bernard, Guillaume Beslon, David M. Bryson, Patryk Chrabaszcz, Nick Cheney, Antoine Cully, Stephane Doncieux, Fred C. Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan Fischer, Stephanie Forrest, Antoine Fr√©noy, Christian Gagn√©, Leni Le Goff, Laura M. Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole Knibbe, Peter Krcah, Richard E. Lenski, Hod Lipson, Robert MacCurdy, Carlos Maestre, Risto Miikkulainen, Sara Mitri, David E. Moriarty, Jean-Baptiste Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T. Pennock, William F. Punch, Thomas S. Ray, Marc Schoenauer, Eric Shulte, Karl Sims, Kenneth O. Stanley, Fran√ßois Taddei, Danesh Tarapore, et al. (4 additional authors not shown) Evolving Neural Networks ‚Äî Risto Miikkulainen Recombination of Artificial Neural Networks ‚Äî Aaron Vose, Jacob Balma, Alex Heye, Alessandro Rigazzi, Charles Siegel, Diana Moise, Benjamin Robbins, Rangan Sukumar Nevergrad: An open source tool for derivative-free optimization ‚Äî J. Rapin and O. Teytaud Evolved Policy Gradients ‚Äî Rein Houthooft, Richard Y. Chen, Phillip Isola, Bradly C. Stadie, Filip Wolski, Jonathan Ho, Pieter Abbeel Using Evolutionary AutoML to Discover Neural Network Architectures ‚Äî Google AI Neural architecture search has advanced to the point where it can outperform human-designed models. ‚Äú‚Ä¶ evolution ‚Äî whether biological or computational ‚Äî is inherently creative, and should routinely be expected to surprise, delight, and even outwit us.‚Äú ‚Äî The Surprising Creativity of Digital Evolution, Lehman et al. 2.2 Deep Reinforcement LearningIn reinforcement learning, an agent interacts with an environment through a Markov decision process. The goal in reinforcement learning is to train the agent to maximize the sum of future rewards, called the return. Reinforcement Learning: An Introduction ‚Äî Andrew Barto and Richard S. Sutton Spinning Up as a Deep RL Researcher ‚Äî Joshua Achiam Intuitive RL: Intro to Advantage-Actor-Critic (A2C) ‚Äî Rudy Gilman Simple Beginner‚Äôs guide to Reinforcement Learning &amp; its implementation ‚Äî Faizan Shaikh Spinning Up in Deep RL ‚Äî Joshua Achiam AlphaStar: Mastering the Real-Time Strategy Game StarCraft II ‚Äî Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg, Wojtek Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Dani Yogatama, Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps, Koray Kavukcuoglu, Demis Hassabis, David Silver Creating a Zoo of Atari-Playing Agents to Catalyze the Understanding of Deep Reinforcement Learning ‚Äî Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Yulun Li, Jeff Clune, Joel Lehman An Introduction to Deep Reinforcement Learning ‚Äî Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau Welcome to Spinning Up in Deep RL! ‚Äî OpenAI A (Long) Peek into Reinforcement Learning ‚Äî Lilian Weng A Theoretical Analysis of Deep Q-Learning ‚Äî Zhuora Yang, Yuchen Xie, Zhaoran Wang Monte Carlo Tree Search ‚Äì beginners guide ‚Äî Kamil Czarnog√≥rski Quantifying Generalization in Reinforcement Learning ‚Äî OpenAI Relational Deep Reinforcement Learning ‚Äî Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia Getting Started With MarathonEnvs v0.5.0a ‚Äî Joe Booth AlphaZero: Shedding new light on the grand games of chess, shogi and Go ‚Äî David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis DQN Adventure: from Zero to State of the Art ‚Äî higgsfield SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark ‚Äî Linxi Fan, Yuke Zhu, Jiren Zhu, Zihua Liu, Anchit Gupta, Joan Creus-Costa, Silvio Savarese, Li Fei-Fei Learning to Act by Predicting the Future ‚Äî Alexey Dosovitskiy, Vladlen Koltun AlphaFold: Using AI for scientific discovery ‚Äî Andrew Senior, John Jumper, Demis Hassabis POET: Endlessly Generating Increasingly Complex and Diverse Learning Environments and their Solutions through the Paired Open-Ended Trailblazer ‚Äî Rui Wang, Joel Lehman, Jeff Clune, Kenneth O. Stanley Reinforcement Learning with Prediction-Based Rewards ‚Äî Yura Burda, Harri Edwards, OpenAI Playing hard exploration games by watching YouTube Paper | YouTube ‚Äî Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang, Nando de Freitas Exploration by Random Network Distillation Paper | Code ‚Äî Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov Large-Scale Study of Curiosity-Driven Learning Paper | Code ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros OpenAI Baselines : A2C | ACER | ACKTR | DDPG | DQN | GAIL | HER | PPO2 | TRPO ‚Äî OpenAI Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines Docs | Blog | Code ‚Äî Antonin Raffin TRPO-GAE Blog | arXiv | arXiv ‚Äî OpenAI Improvised Robotic Design with Found Objects ‚Äî Azumi Maekawa, Ayaka Kume, Hironori Yoshida, Jun Hatori, Jason Naradowsky, Shunta Saito A3C arXiv | Medium | Code ‚Äî OpenAI Deep Reinforcement Learning ‚Äî Sergey Levine Vel: PyTorch meets baselines ‚Äî Jerry Continual Match Based Training in Pommerman: Technical Report ‚Äî Peng Peng, Liang Pang, Yufeng Yuan, Chao Gao Actor-Critic Policy Optimization in Partially Observable Multiagent Environments ‚Äî Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat, Karl Tuyls, Remi Munos, Michael Bowling TensorFlow Reinforcement Learning ‚Äî DeepMind TensorFlow Agents ‚Äî TensorFlow TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess Live Demo | Code ‚Äî Fran√ßois Pays DiCE: The Infinitely Differentiable Monte Carlo Estimator ‚Äî Vitaly Kurin, Jakob Foerster, Shimon Whiteson TorchCraftAI: A bot platform for machine learning research on StarCraft¬Æ: Brood War¬Æ ‚Äî Facebook Curiosity and Procrastination in Reinforcement Learning ‚Äî Nikolay Savinov, Timothy Lillicrap Hierarchical Actor-Critic ‚Äî Andrew Levy, Robert Platt, Kate Saenko Montezuma‚Äôs Revenge Solved by Go-Explore, a New Algorithm for Hard-Exploration Problems ‚Äî Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley, Jeff Clune Computational Theories of Curiosity-Driven Learning ‚Äî Pierre-Yves Oudeyer Depth-Limited Solving for Imperfect-Information Games ‚Äî Noam Brown, Tuomas Sandholm, Brandon Amos Optimizing Expectations: From Deep Reinforcement Learning to Stochastic Computation Graphs ‚Äî John Schulman Neural Episodic Control ‚Äî Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adri√† Puigdom√®nech, Oriol Vinyals, Demis Hassabis, Daan Wierstra, Charles Blundell RLlib: Abstractions for Distributed Reinforcement Learning ‚Äî Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox, Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning ‚Äî Gregory Farquhar, Tim Rockt√§schel, Maximilian Igl, Shimon Whiteson Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning ‚Äî Fabio Pardo, Vitaly Levdik, Petar Kormushev Learning to Search with MCTSnets ‚Äî Arthur Guez, Th√©ophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals, Daan Wierstra, R√©mi Munos, David Silver Convergence of Value Aggregation for Imitation Learning ‚Äî Ching-An Cheng, Byron Boots Dopamine : DQN | C51 | Rainbow | Implicit Quantile Network ‚Äî Marc G. Bellemare, Pablo Samuel Castro, Carles Gelada, Saurabh Kumar, Subhodeep Moitra S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) for Robotics ‚Äî Antonin RAFFIN Advanced Deep Learning and Reinforcement Learning ‚Äî DeepMind Researchers Reinforcement Learning for Improving Agent Design arXiv | Blog ‚Äî David Ha Deep Reinforcement Learning from Human Preferences arXiv | Blog | Code ‚Äî OpenAI Introduction to Learning to Trade with Reinforcement Learning ‚Äî Denny Britz Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience ‚Äî Yevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan Issac, Nathan Ratliff, Dieter Fox Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning ‚Äî Frederik Ebert, Sudeep Dasari, Alex X. Lee, Sergey Levine, Chelsea Finn CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning ‚Äî C√©dric Colas, Olivier Sigaud, Pierre-Yves Oudeyer Bayesian Optimization in AlphaGo ‚Äî Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian Schrittwieser, David Silver, Nando de Freitas One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL ‚Äî Tom Le Paine, Sergio G√≥mez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David Budden, Nando de Freitas Optimizing Agent Behavior over Long Time Scales by Transporting Value ‚Äî Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico Carnevale, Arun Ahuja, Greg Wayne Large-Scale Study of Curiosity-Driven Learning ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning ‚Äî Alexander Clegg, Wenhao Yu, Jie Tan, C. Karen Liu, Greg Turk, SIGGRAPH Asia 2018 Automatic Poetry Generation with Mutual Reinforcement Learning ‚Äî Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Wenhao Li Learning to Communicate with Deep Multi-Agent Reinforcement Learning in PyTorch ‚Äî Minqi Jiang Learning to Navigate the Web ‚Äî Anonymous Understanding &amp; Generalizing AlphaGo Zero ‚Äî Anonymous Deep RL Bootcamp ‚Äî Pieter Abbeel, Yan (Rocky) Duan, Xi (Peter) Chen, Andrej Karpathy 2.2.1 Model-Based RLIn Model-Based RL, the agent generates predictions about the next state and reward before choosing each action. World Models ‚Äî David Ha, J√ºrgen Schmidhuber Imagination-Augmented Agents for Deep Reinforcement Learning ‚Äî Th√©ophane Weber, S√©bastien Racani√®re, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom√®nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra Learning Latent Dynamics for Planning from Pixels ‚Äî Hafner et al. Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero) ‚Äî Silver et al. ‚ÄúNo superintelligent AI is going to bother with a task that is harder than hacking its reward function.‚Äú ‚Äî The Lebowski theorem 2.3 Self PlaySelf-play mirrors similar insights from coevolution. AlphaGo Zero showed that algorithms matter much more than big data and massive amounts of computation: ‚ÄúSelf-Play is Automated Knowledge Creation.‚Äú ‚Äî Carlos E. Perez Transfer learning is the key to go from self-play to the real world. Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks ‚Äî Zenan Ling, Haotian Ma, Yu Yang, Robert C. Qiu, Song-Chun Zhu, Quanshi Zhang Deep Learning: AlphaGo Zero Explained In One Picture ‚Äî L.V. How to build your own AlphaZero AI using Python and Keras ‚Äî David Foster An open-source implementation of the AlphaGoZero algorithm ‚Äî TensorFlow ELF OpenGo: An Open Reimplementation of AlphaZero ‚Äî Tian et al. TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess. Live Demo | Code ‚Äî Fran√ßois Pays 2.4 Multi-Agent Populations Machine Theory of Mind ‚Äî Rabinowitz et al. A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning ‚Äî Lanctot et al. Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments ‚Äî Al-Shedivat et al. Intrinsic Social Motivation via Causal Influence in Multi-Agent RL ‚Äî Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems ‚Äî Stefano V. Albrecht, Peter Stone Learning with Opponent-Learning Awareness Paper | Blog ‚Äî OpenAI GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning Paper | Blog ‚Äî Jacky Liang, Viktor Makoviychuk, Ankur Handa, Nuttapong Chentanez, Miles Macklin, Dieter Fox, NVIDIA Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Paper | Blog | Code ‚Äî OpenAI 2.5 Deep Meta-LearningLearning to Learn. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. A meta-learning algorithm takes in a distribution of tasks, where each task is a learning problem, and it produces a quick learner ‚Äî a learner that can generalize from a small number of examples. Learning to Learn Paper | Code ‚Äî Google DeepMind, University of Oxford, Canadian Institute for Advanced Research Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks ‚Äî Chelsea Finn, Pieter Abbeel, Sergey Levine AutoML: Methods, Systems, Challenges ‚Äî Frank Hutter, Lars Kotthoff, Joaquin Vanschoren Causal Reasoning from Meta-reinforcement Learning ‚Äî Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, Zeb Kurth-Nelson The Evolved Transformer ‚Äî David R. So, Chen Liang, Quoc V. Le Talos: Hyperparameter Scanning and Optimization for Keras ‚Äî Autonomio EAT-NAS: Elastic Architecture Transfer for Accelerating Large-scale Neural Architecture Search ‚Äî Jiemin Fang, Yukang Chen, Xinbang Zhang, Qian Zhang, Chang Huang, Gaofeng Meng, Wenyu Liu, Xinggang Wang FIGR: Few-shot Image Generation with Reptile ‚Äî Louis Clou√¢tre, Marc Demers Efficient Neural Architecture Search via Parameter Sharing Paper | Code ‚Äî Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean Meta-Learning Shared Hierarchies Paper | Blog | Code ‚Äî OpenAI Learning Unsupervised Learning Rules ‚Äî Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein Reptile: A Scalable Meta-Learning Algorithm ‚Äî Alex Nichol, John Schulman Learning Shared Dynamics with Meta-World Models ‚Äî Lisheng Wu, Minne Li, Jun Wang NIPS2017 Meta Learning Symposium videos ‚Äî NIPS 2017 Colaboratory reimplementation of MAML in TF 2.0 ‚Äî Marianne Linhares Monteiro ‚ÄúThe notion of a neural ‚Äúarchitecture‚Äù is going to disappear thanks to meta learning.‚Äú ‚Äî Andrew Trask 3. Environments3.1 OpenAI Gym OpenAI Gym WebSite | Blog | GitHub | White Paper ‚Äî OpenAI 3.2 Unity ML-Agents Unity ML-Agents WebSite | GitHub | Documentation | Challenge I ‚Äî Unity Technologies Puppo, The Corgi: Cuteness Overload with the Unity ML-Agents Toolkit ‚Äî Vincent-Pierre Berges, Leon Chen 3.3 DeepMind Control Suite DeepMind Control Suite Paper | GitHub | Video ‚Äî DeepMind 3.4 Brigham Young University | Holodeck BYU Holodeck: A high-fidelity simulator for deep reinforcement learning Website | GitHub | Documentation ‚Äî Brigham Young University 3.5 Facebook‚Äôs Horizon Horizon: Facebook‚Äôs Open Source Applied Reinforcement Learning Platform Paper | GitHub | Blog ‚Äî Jason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye 3.6 PhysX PhysX SDK, an Open-Source Physics Engine GitHub | Blog ‚Äî NVIDIA 4. General Readings, Ressources and Tools Building safe artificial intelligence: specification, robustness, and assurance ‚Äî Pedro A. Ortega, Vishal Maini, and the DeepMind safety team Google Dataset Search Beta ‚Äî Google Papers with Code ‚Äî Papers with Code GitXiv | arXiv + CODE ‚Äî Collaborative Open Computer Science Best Paper Awards in Computer Science (since 1996) ‚Äî Jeff Huang The Vulnerable World Hypothesis ‚Äî Nick Bostrom Podcast: Existential Hope in 2019 and Beyond ‚Äî Ariel Conn Scalable agent alignment via reward modeling Medium | arXiv ‚Äî Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, Shane Legg The 2018 AI Index report ‚Äî Yoav Shoham, Raymond Perrault, Erik Brynjolfsson, Jack Clark, James Manyika, Juan Carlos Niebles, Terah Lyons, John Etchemendy, Barbara Grosz, Zoe Bauer ASILOMAR AI PRINCIPLES ‚Äî The 2017 Asilomar conference Strategic Implications of Openness in AI Development ‚Äî Nick Bostrom ‚Äú(AI) will rank among our greatest technological achievements, and everyone deserves to play a role in shaping it.‚Äú ‚Äî Fei-Fei Li Artificial Intelligence and Human Rights ‚Äî Jessica Fjeld, Hannah Hilligoss, Nele Achten, Maia Levy Daniel, Sally Kagay, and Joshua Feldman (Visualization Designed By: Arushi Singh) teleportHQ ThinkToCode ecosystem ‚Äî teleportHQ Statistical physics of liquid brains ‚Äî Jordi Pinero and Ricard Sole Reframing Superintelligence ‚Äî K. Eric Drexler Interpretable Machine Learning ‚Äî Christoph Molnar Building a Winning Self-Driving Car in Six Months ‚Äî Keenan Burnett, Andreas Schimpe, Sepehr Samavi, Mona Gridseth, Chengzhi Winston Liu, Qiyang Li, Zachary Kroeze, Angela P. Schoellig Une intelligence artificielle bien r√©elle : les termes de l‚ÄôIA ‚Äî Office qu√©b√©cois de la langue fran√ßaise How to deliver on Machine Learning projects ‚Äî Emmanuel Ameisen The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation ‚Äî Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn, Se√°n √ì h√âigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei Machine Learning for Combinatorial Optimization: a Methodological Tour d‚ÄôHorizon ‚Äî Yoshua Bengio, Andrea Lodi, Antoine Prouvost 26-Year-Old Nigerian Creates First Gaming Robot ‚Äî Christina Santi Machine Learning Top 10 Articles for the Past Month (v.Oct 2018) ‚Äî Mybridge Is artificial intelligence set to become art‚Äôs next medium? ‚Äî Jonathan Bastable, Christie‚Äôs Phrase-Based &amp; Neural Unsupervised Machine Translation arXiv | Code | Blog ‚Äî Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc‚ÄôAurelio Ranzato Tensor Considered Harmful ‚Äî Alexander Rush An Artificial Neuron Implemented on an Actual Quantum Processor ‚Äî Tacchino et al. Efficiently measuring a quantum device using machine learning ‚Äî D.T. Lennon, H. Moon, L.C. Camenzind, Liuqi Yu, D.M. Zumb√ºhl, G.A.D. Briggs, M.A. Osborne, E.A. Laird, N. Ares Deep Learning : Current Limits and What Lies Beyond Them ‚Äî Fran√ßois Chollet Open-ended Learning in Symmetric Zero-sum Games ‚Äî David Balduzzi, Marta Garnelo, Yoram Bachrach, Wojtek Czarnecki, Julien Perolat, Max Jaderberg, Thore Graepel Poker | Solving Imperfect-Information Games via Discounted Regret Minimization ‚Äî Noam Brown, Tuomas Sandholm Automatically Generating Comments for Arbitrary Source Code) ‚Äî Jessica Moore The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ‚Äî Jay Alammar 10 Exciting Ideas of 2018 in NLP ‚Äî Sebastian Ruder Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters ‚Äî Jesse Vig Learning to Infer Graphics Programs from Hand-Drawn Images ‚Äî Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum TensorFlow code and pre-trained models for BERT (Bidirectional Encoder Representations from Transformers) ‚Äî Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents ‚Äî Nick Bostrom MobiLimb: Augmenting Mobile Devices with a Robotic Limb ‚Äî Marc Teyssier, Gilles Bailly, Catherine Pelachaud, Eric Lecolinet 32-Legged Spherical Robot Moves Like an Amoeba ‚Äî Evan Ackerman, IEEE Spectrum On winning all the big academic recent competitions. Presentation. ‚Äî Megvii (Face++) Team Stanford AI recreates chemistry‚Äôs periodic table of elements ‚Äî Ker Than Neural Approaches to Conversational AI ‚Äî Jianfeng Gao, Michel Galley, Lihong Li Learned optimizers that outperform SGD on wall-clock and validation loss ‚Äî Luke Metz, Niru Maheswaranathan, Jeremy Nixon, C. Daniel Freeman, Jascha Sohl-Dickstein Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing ‚Äî Elia Kaufmann, Mathias Gehrig, Philipp Foehn, Ren√© Ranftl, Alexey Dosovitskiy, Vladlen Koltun, Davide Scaramuzza Writing Code for NLP Research ‚Äî Allen Institute for Artificial Intelligence Autonomous Tidying-up Robot System ‚Äî Preferred Networks Emerging Technology and Ethics Research Guide ‚Äì v 1.0 ‚Äî Danya Glabau Machine learning and artificial intelligence in the quantum domain ‚Äî Vedran Dunjko, Hans J. Briegel Playing Mortal Kombat with TensorFlow.js. Transfer learning and data augmentation ‚Äî Minko Gechev A series on quantum computing? Welcome to QuantumCasts! ‚Äî Marissa Giustina NLP.js : a general natural language utilities for nodejs ‚Äî AXA Shared Services Spain S.A. Hierarchical Multi-Task Learning model: One NLP model to rule them all! Medium | Demo | Code ‚Äî Hugging Face Constructing exact representations of quantum many-body systems with deep neural networks ‚Äî Giuseppe Carleo Over 200 of the Best Machine Learning, NLP, and Python Tutorials ‚Äî 2018 Edition ‚Äî Robbie Allen Deep Learning Papers Reading Roadmap ‚Äî Flood Sung Learn Machine Learning from Top 50 Articles for the Past Year (v.2019) ‚Äî Mybridge Open Courses and Textbooks ‚Äî Samuel G. Finlayson ~250 awesome short lectures on robotics ‚Äî Queensland University of Technology Robot Academy The Best Textbooks on Every Subject ‚Äî lukeprog ‚ÄúML paper writing pro-tip: you can download the raw source of any arxiv paper. Click on the ‚ÄúOther formats‚Äù link, then click ‚ÄúDownload source‚Äù. This gets you a .tar.gz with all the .tex files, all the image files for the figures in their original resolution, etc.‚Äú ‚Äî Ian Goodfellow Webinaire international IA 101 sur l‚Äôintelligence artificielleIl s‚Äôagit d‚Äôun √©v√©nement en ligne. Les participant(e)s recevront un lien pour se joindre √† l‚Äô√©v√©nement juste avant celui-ci. Aper√ßu du programme (‚ÄúInstituer une compr√©hension percutante l‚ÄôIA‚Äù) et billets: https://ai101webinar.eventbrite.ca Langue: Ce cours (webinaire) destin√© √† une audience internationale est en anglais. R√©servation de groupe: ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IA101 #IntelligenceArtificielle #IntelligenceArtificielle101 #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/academie/index.html"},{"title":"MONTR√âAL.IA | Intelligence Artificielle Montr√©al","text":"AVIS L√âGALCECI EST UN LOGICIEL / SYST√àME DE MONTR√âAL.IA. LES INFORMATIONS DONN√âES PAR CE LOGICIEL / SYST√àME SONT FOURNIES SANS GARANTIE D‚ÄôAUCUNE SORTE ET NE CONSTITUENT PAS UNE APPROBATION. LE LOGICIEL / SYST√àME EST FOURNI ‚ÄúTEL QUEL‚Äù, SANS GARANTIE D‚ÄôAUCUNE SORTE, EXPLICITE OU IMPLICITE, NOTAMMENT SANS GARANTIE DE QUALIT√â MARCHANDE, D‚ÄôAD√âQUATION √Ä UN USAGE PARTICULIER ET D‚ÄôABSENCE DE CONTREFA√áON. EN AUCUN CAS, MONTR√âAL.IA, LES AUTEURS OU TITULAIRES DU DROIT D‚ÄôAUTEUR NE SERONT RESPONSABLES DE TOUT DOMMAGE, R√âCLAMATION OU AUTRE RESPONSABILIT√â, QUE CE SOIT DANS LE CADRE D‚ÄôUN CONTRAT, D‚ÄôUN D√âLIT OU AUTRE, EN PROVENANCE DE, CONS√âCUTIF √Ä OU EN RELATION AVEC LE LOGICIEL / SYST√àME OU SON UTILISATION, OU AVEC D‚ÄôAUTRES √âL√âMENTS DU LOGICIEL / SYST√àME. LES PREUVES D‚ÄôUTILISATION NON AUTORIS√âE PEUVENT ETRE TRANSMISES AU PERSONNEL APPROPRI√â POUR DES ACTIONS ADMINISTRATIVES, P√âNALES OU D‚ÄôAUTRES ACTIONS L√âGALES.‚Äã ‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚úâÔ∏è Courriel : info@montreal.ai‚Äãüìû T√©l√©phone : +1.514.829.8269‚Äãüåê Site web : http://www.montreal.ai/‚Äãüìù LinkedIn : https://www.linkedin.com/in/montrealai/‚Äãüèõ Si√®ge social : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/legal/index.html"},{"title":"MONTR√âAL.IA | Intelligence artificielle Montr√©al","text":"MONTR√âAL.IA A√âROSPATIALUne nouvelle √®re de d√©couvertes scientifiques surhumaines. ‚ÄúMon objectif est simple. C‚Äôest la compr√©hension compl√®te de l‚Äôunivers, pourquoi il est tel qu‚Äôil est et pourquoi il existe.‚Äú ‚Äî Stephen Hawking Un parcours l√©gendaire | Comment tout a commenc√© ‚Äî D√©couvrez la gen√®se de cet exceptionnel cheminement: Vincent Boucher | ‚Ä¶ un cerveau de l‚Äôa√©rospatial! ‚Äî Le journal de Montr√©al √âtoiles filantes | Vincent Boucher ‚Äî Le bulletin des employ√©s de l‚ÄôAgence spatiale canadienne Vincent Boucher | Un (jeune) homme d‚Äôexception ‚Äî Nathalie Petrowski, La Presse Montr√©al.IA A√©rospatial: Vision globaleIA + A√©ronautique | Physique | Robotique Vision : √ätre la pierre angulaire de l‚Äôindustrie de l‚ÄôIA a√©rospatiale. ‚ÄúConscients que Montr√©al est un p√¥le mondial de l‚Äôindustrie a√©rospatiale et un chef de file international en intelligence artificielle, nous avons fond√© Montr√©al.IA A√©rospatial.‚Äú ‚Äî Vincent Boucher, B. Sc. Physique, M.A. Analyse des politiques gouvernementales et M. Sc. G√©nie a√©rospatial (technologie spatiale), pr√©sident-fondateur de Montr√©al.IA Montr√©al.IA A√©rospatial a un statut particulier dans le portefolio de Montr√©al.IA. ‚ÄúCe que je ne peux pas cr√©er, je ne peux pas le comprendre.‚Äú ‚Äî Richard Feynman Montr√©al.IA A√©rospatial: Relever les d√©fis les plus difficilesNous sommes au seuil d‚Äôun changement technologique mondial. Montr√©al.IA A√©rospatial s‚Äôappuie sur l‚Äôing√©nierie a√©rospatiale, l‚Äôintelligence artificielle appliqu√©e et la recherche en astrophysique pour optimiser les vols spatiaux, l‚Äôefficacit√© des satellites, et l‚Äôexploration spatiale √† une √©chelle sans pr√©c√©dent. Un nouveau mod√®le puissant pour un grand nombre de g√©ants √©mergents de la superintelligence appara√Æt dans le paysage scientifique. ‚ÄúToute technologie suffisamment avanc√©e est indissociable de la magie.‚Äú ‚Äî Arthur C. Clarke Montr√©al.IA A√©rospatial: Explorer les √©toiles et l‚ÄôUniversNous vivons une p√©riode de perc√©es scientifiques incroyables. Les progr√®s √† venir, au carrefour de l‚Äôing√©nierie a√©rospatiale et de l‚Äôintelligence artificielle, ouvrent des perspectives extraordinaires pour l‚Äôavenir de l‚ÄôHumanit√©. ‚ÄúArtificial Intelligence is about recognising patterns, Artificial Life is about creating patterns.‚Äú ‚Äî Mizuki Oka et al, #alife2018 Montr√©al.IA A√©rospatial croit √† l‚Äô√©panouissement de l‚ÄôHumanit√© en misant sur la superintelligence pour explorer les √©toiles: l‚Äôendroit o√π nous appartenons tous vraiment. Avec plus d‚Äôing√©niosit√©, nous mettons en ≈ìuvre des agents IA tr√®s performants pour concevoir des algorithmes d‚Äôapprentissage en profondeur innovants comprenant notre Univers. ‚ÄúI think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from.‚Äú ‚Äî Demis Hassabis Les agents IA surhumains de Montr√©al.IA peuvent tirer des le√ßons des enseignements par l‚Äôexp√©rience, simuler des mondes et orchestrer des m√©ta-solutions. Montr√©al.IA A√©rospatial offre une nouvelle √®re globale de prouesses techniques percutantes √† un niveau tr√®s √©lev√©. ‚ÄúBien s√ªr, les physiciens des particules ont √©t√© parmi les premiers √† comprendre que la nature est compositionnelle.‚Äú ‚Äî Yann LeCun R√©f√©rences Why does deep and cheap learning work so well? ‚Äî Henry W. Lin, Max Tegmark, David Rolnick Introduction to astroML: Machine Learning for Astrophysics ‚Äî Jacob VanderPlas, Andrew J. Connolly, ZÀáeljko Ivezic ÃÅ, Alex Gray CosmoFlow: Using Deep Learning to Learn the Universe at Scale ‚Äî Mathuriya et al. Bayesian Deep Learning for Exoplanet Atmospheric Retrieval ‚Äî Frank Soboczenski, Michael D. Himes, Molly D. O‚ÄôBeirne, Simone Zorzan, Atilim Gunes Baydin, Adam D. Cobb, Daniel Angerhausen, Giada N. Arney, Shawn D. Domagal-Goldman Galaxy morphology prediction using capsule networks ‚Äî Katebi et al. Machine Learning for Physics and the Physics of Learning ‚Äî Steve Brunton, Cecilia Clementi, Yann LeCun, Marina Meila, Frank Noe, Francesco Paesani MINERVA-II1: Successful image capture, landing on Ryugu and hop! ‚Äî JAXA | Japan Aerospace Exploration Agency Restricted Boltzmann Machines for Collaborative Filtering ‚Äî Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton A Practical Guide to Training Restricted Boltzmann Machines ‚Äî Geoffrey Hinton GAIA DATA RELEASE 1 ‚Äî European Space Agency Evolved Virtual Creatures, Evolution Simulation, 1994 ‚Äî Karl Sims PHYSICS | MACHINE LEARNING - Recent papers combining the fields of physics and machine learning ‚Äî physicsml AI Model Could Help Robots Navigate on the Moon and Mars Without GPS ‚Äî NVIDIA Machine Learning and Likelihood-Free Inference in Particle Physics Slides | Video ‚Äî Kyle Cranmer Enabling Dark Energy Science with Deep Generative Models of Galaxy Images ‚Äî Siamak Ravanbakhsh, Francois Lanusse, Rachel Mandelbaum, Jeff Schneider, Barnabas Poczos Unity and DeepMind to Advance AI Research Using Virtual Worlds ‚Äî Business Wire A look at deep learning for science ‚Äî Prabhat Searching for Exotic Particles in High-Energy Physics with Deep Learning ‚Äî Pierre Baldi, Peter Sadowski, Daniel Whiteson Estimating Cosmological Parameters from the Dark Matter Distribution ‚Äî Siamak Ravanbakhsh, Junier Oliva, Sebastien Fromenteau, Layne C. Price, Shirley Ho, Jeff Schneider, Barnabas Poczos ‚ÄúMONTEZ DANS LA FUS√âE‚Äù: Rejoignez Montr√©al.IA A√©rospatial!R√©unissant des contributions de chercheurs reconnus comme √©tant les principales autorit√©s dans leur domaine, Montr√©al.IA A√©rospatial est en avance sur une tendance qui influencera profond√©ment l‚Äôavenir de l‚ÄôHumanit√©. Montr√©al.IA A√©rospatial est √† la recherche d‚Äôassoci√©s et de partenaires prosp√®res: capitaines d‚Äôindustrie, philanthropes, entrepreneurs en technologie de pointe, financiers and √©rudits de haut vol pour se joindre √† notre √©quipe dans cette t√¢che aux proportions historiques. ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/aerospatial/index.html"},{"title":"MONTR√âAL.IA | Intelligence Artificielle Montr√©al","text":"LES BEAUX-ARTS IA DE MONTR√âAL.IA (version pr√©liminaire)Red√©finition de l‚Äôhistoire de l‚Äôart | Lancement d‚Äôenvergure dans les grandes capitales Qu√©bec, Montr√©al, Vancouver, Saint-Martin, Beverly Hills, Panama, Br√©sil, Paris, Milan, Principaut√© de Monaco, Gen√®ve, Belgique, Allemagne, Luxembourg, Espagne, Autriche, Londres, F√©d√©ration de Russie, Aspen, Maui, SoHo, Isra√´l , La Jolla, Macao, Duba√Ø, Inde, Qatar, Arabie Saoudite, Beijing, Shanghai, Hong Kong, Tokyo et Tapei. Naissance des Beaux-Arts IA ‚Äî Montr√©al.IA pr√©sente un nouveau mouvement artistique. ‚ÄúLes artistes qui cr√©eront avec l‚ÄôIA ne suivront pas les tendances, ils les d√©termineront.‚Äú ‚Äî Les Beaux-Arts de Montr√©al.IA Un m√©lange d‚Äôart, de culture et de science dans l‚Äôesprit de L√©onard de Vinci. Ouvrant la porte √† un nouveau mouvement artistique au 21 √®me si√®cle, les Beaux-Arts de Montr√©al.IA suscite d√©j√† un √©moi parmi les plus grands collectionneurs d‚Äôart ainsi que parmi les personnalit√©s les plus brillantes, les plus influentes et les plus iconoclastes du monde. √Ä la Renaissance, le pape Jules II a commandit√© le peintre Michel-Ange, afin que celui-ci r√©alise le plafond de la chapelle Sixtine au Vatican. Aujourd‚Äôhui, vous pouvez commander, de la m√™me fa√ßon, une ≈ìuvre d‚Äôart IA √† la Maison des Beaux-Arts de Montr√©al.IA. Captivant un public averti, les Beaux-Arts de Montr√©al.IA refl√®te une diversit√© esth√©tique, une richesse conceptuelle et le respect de la cr√©ativit√© la plus pure, exprim√©e par une machine et consid√©r√©e comme la plus √©lev√©e dans la hi√©rarchie des genres. Nous pr√©parons une campagne de relations publiques dans le monde entier avec la participation √† des √©missions t√©l√©vis√©es et avec la confection d‚Äôun documentaire sp√©cialis√©. Un nouveau jour est arriv√© dans monde artistiqueLe 25 octobre 2018, l‚Äôhistoire du march√© de l‚Äôart de l‚ÄôIA a √©t√© chamboul√©e. La premi√®re ≈ìuvre d‚Äôart en intelligence artificielle a √©t√© vendue aux ench√®res de Christie‚Äôs et a boulevers√© les attentes en atteignant 432 500 dollars. R√©f√©rences The first AI artwork to be sold in a major auction achieves $432,500 after a bidding battle on the phones and via ChristiesLive ‚Äî Christie‚Äôs A sign of things to come? AI-produced artwork sells for $433K, smashing expectations ‚Äî Allyssia Alleyne, CNN Eerie AI-generated portrait fetches $432,500 at auction ‚Äî Devin Coldewey, TechCrunch ‚ÄúUn porte-parole de Christie‚Äôs nous a parl√© de l‚Äôexcitation du march√© face √† ce changement important: ‚ÄúNous pouvons confirmer qu‚Äôil y avait cinq soumissionnaires diff√©rents de toutes les r√©gions du monde qui √©taient en concurrence pour le lot √† ce prix √©lev√©, ce qui semble √™tre un bon indice de l‚Äôint√©r√™t des collectionneurs et du potentiel de march√© futur pour l‚Äôart de l‚Äôintelligence artificielle en g√©n√©ral‚Ä¶‚Äù‚Äú ‚Äî Adam Heardman, MutualArt La Maison des Beaux-Arts de Montr√©al.IAHistoire des Beaux-arts de l‚ÄôIA: la construction d‚Äôun h√©ritage La Maison des Beaux-Arts de Montr√©al.IA est en avance sur une tendance qui aura un impact profond sur l‚Äôindustrie internationale de la mode, des beaux-arts et de la joaillerie, qui est un march√© d‚Äôune valeur de 350 milliards de dollars par an ( üåê http://www.billionaire.tv/TheGazette.pdf ). Un renouveau des grands id√©aux de la Renaissance. | Les agents d‚Äôintelligence artificielle de la Maison des Beaux-Arts de Montr√©al.IA se bonifient par leurs enseignements acquis gr√¢ce √† leurs exp√©riences pour concevoir des ≈ìuvres d‚Äôart et une vision surhumaines! Nos cr√©ations sont des purs objets de d√©sir √©voquant les contes de f√©es et les r√™ves enchant√©s et traduisent un sentiment d‚Äôexclusivit√©: une po√©sie fascinante, originale et vibrante de l‚ÄôIA. Exaltant l‚Äôapprentissage en profondeur, l‚Äôapprentissage par renforcement, les r√©seaux antagonistes g√©n√©ratifs, le m√©ta-apprentissage et l‚Äôauto-apprentissage √† une √©chelle v√©ritablement mondiale et pour d√©ployer avec passion et avec une inhabituelle √©l√©gance une nouvelle approche, la Maison des Beaux-Arts de Montr√©al. IA propose des cr√©ations surhumaines et des designs r√©volutionnaires g√©n√©r√©s par l‚ÄôIA, qui sont uniques en leur genre, d√©voilant un monde majestueux de secrets cach√©s: ‚ùñ Le parfum de l‚ÄôIA (parfums)Une ligne aussi enchanteresse que les muses qu‚Äôelle inspire. ‚ùñ Haute-Joaillerie IA Multi-Mondes ( üíé )Une collection qui est sur le point de red√©finir l‚Äôindustrie du diamant du XXI√®me si√®cle.La Maison des Beaux-Arts de Montr√©al.IA est pionni√®re dans les nouvelles coupes de diamants et atteint un sommet sans pr√©c√©dent en mati√®re de brillance, de scintillement et de dispersion pour les fashionistas qui d√©finiront les tendances de la haute-joaillerie de notre √©poque. ‚ùñ Oeuvres d‚Äôart (sign√©es: Montr√©al.IA)Des oeuvres originales num√©rot√©es et sign√©es, certificat d‚Äôauthenticit√© compris. Une odyss√©e au coeur univers parall√®les cosmologiques, divins et mythologiques rendue possible par l‚ÄôIA. Une histoire l√©gendaire: la source d‚Äôun h√©ritage exceptionnelLe secr√©tariat g√©n√©ral du Conseil ex√©cutif des Beaux-Arts de Montr√©al.IA Catalyseur professionnel et exp√©riment√© dans les domaines de la recherche innovante, de l‚Äôing√©nierie financi√®re et du luxe international, le pr√©sident-fondateur de Montr√©al.IA, Vincent Boucher, a re√ßu le 15 octobre 2009, le prestigieux certificat Record du monde Guinness pour sa Tourmaline Paraiba taill√©e la plus importante au monde. Un travail d‚Äôinnovation intellectuelle, esth√©tique et technique | La clairvoyance strat√©gique de Vincent Boucher et sa capacit√© √† mener l‚Äôun des projets les plus ambitieux de l‚ÄôHistoire lui ont permis de se positionner √† la fine pointe de son domaine et de se forger une r√©putation bien m√©rit√©e √† l‚Äô√©chelle mondiale. ‚ÄúL‚Äôhomme d‚Äôaffaires (Vincent Boucher) acquiert la pierre la plus rare au monde.‚Äù‚Äú ‚Äî Mike King, The Gazette Magnifiant les cr√©ations les plus pures et les plus belles, en proposant un enseignement et des recherches r√©v√©lant des aspects uniques d‚Äôun point de vue critique, intellectuel et historique et en ouvrant les portes √† un nouveau mouvement artistique, la Maison des Beaux-Arts de Montr√©al.IA alimente la passion qui anime les artistes de l‚ÄôIA les plus performants du moment. D√©finir le genre des Beaux-Arts en IAUn sentiment de myst√®re‚Ä¶ et une compr√©hension profonde du monde, des gens et de la nature humaine. ‚ÄúPour identifier les ≈ìuvres v√©ritablement novatrices, nous ferions mieux de cesser de nous questionner √† savoir o√π se situe la fronti√®re entre le travail de l‚Äôartiste et l‚Äôutilisation des outils de l‚ÄôIA, et de plut√¥t commencer √† nous demander si des artistes humains utilisent l‚ÄôIA pour approfondir leurs concepts et leur esth√©tisme plus que les chercheurs ou codeurs.‚Äú ‚Äî Tim Schneider et Naomi Rea, artnet, 25 septembre 2018 Apprentissage en profondeur + Apprentissage par renforcement + R√©seaux antagonistes g√©n√©ratifs + M√©ta-apprentissage + Auto-apprentissage R√©f√©rences Data Science, Machine Learning and Artificial Intelligence for Art ‚Äî Vishal Kumar Scaling the Mission: The Met Collection API (406,000 images of over 205,000 CC0 objects) ‚Äî Loic Tallon, Chief Digital Officer What do 50 million drawings look like? ‚Äî Google Neural scene rendering: Transfer learning to render a fruit still life from photos ‚Äî Brett G√∂hre GAN Lab: Play with Generative Adversarial Networks (GANs) in your browser! Web | Paper ‚Äî Minsuk Kahng, Nikhil Thorat, Polo Chau, Fernanda Vi√©gas, and Martin Wattenberg Generating Memoji from Photos ‚Äî Pat Niemeyer Playing a game of GANstruction ‚Äî Helena Sarin Large Scale GAN Training for High Fidelity Natural Image Synthesis Paper | TF Hub | Colab ‚Äî Andrew Brock, Jeff Donahue, Karen Simonyan TL-GAN: transparent latent-space GAN ‚Äî SummitKwan TensorFlow-GAN (TFGAN) ‚Äî Joel Shor, Sergio Guadarrama Progressive GANs | Notebook with smooth interpolations through z-space ‚Äî Gene Kogan Self-Attention GAN Paper | Tensorflow implementation ‚Äî Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena Discriminator Rejection Sampling ‚Äî Samaneh Azadi, Catherine Olsson, Trevor Darrell, Ian Goodfellow, Augustus Odena Tensorpack | Generative Adversarial Networks ‚Äî Tensorpack Ngx | Neural network based visual generator and mixer ‚Äî Keijiro Takahashi Magenta Studio (beta) ‚Äî Google AI Differentiable Monte Carlo Ray Tracing through Edge Sampling ‚Äî Tzu-Mao Li, Miika Aittala, Fr√©do Durand, Jaakko Lehtinen A Few Unusual Autoencoders ‚Äî Colin Raffel Deep Variational Reinforcement Learning for POMDPs ‚Äî Maximilian Igl, Luisa Zintgraf, Tuan Anh Le, Frank Wood, Shimon Whiteson Learning Dexterity ‚Äî OpenAI Robots that Learn ‚Äî OpenAI (Self-Play) | OpenAI Five ‚Äî OpenAI TFHub state-of-the-art AutoAugment Modules ‚Äî TensorFlow Creatability: a new collection of experiments exploring ways to make creative tools more accessible ‚Äî Experiments with Google Evolved Virtual Creatures, Evolution Simulation, 1994 ‚Äî Karl Sims Reinforcement Learning for Improving Agent Design: What happens when we let an agent learn a better body design together with learning its task? Article | Paper ‚Äî David Ha ‚ÄúLa technologie de cr√©ation artistique de notre √©poque sera l‚ÄôIA.‚Äú ‚Äî Rama Allen #AI4Artists : R√©v√©lons un monde de secrets cach√©sConfectionner des cr√©ation l√©gendaires: un cours de 75 minutes bien con√ßu pour les artistes Vers qui vous tourneriez-vous si vous souhaitiez apprendre le meilleur de l‚ÄôIA pour les artistes? Le Secr√©tariat g√©n√©ral de MONTR√âAL.IA pr√©sente, en toute l√©gitimit√© par ses connaissance aiguis√©es, toutes les facettes de l‚ÄôIA pour les artistes: ‚Äú#AI4Artists: premier survol mondial de l‚ÄôIA pour les artistes‚Äú. PUISSANT ET UTILE. Ce cours pratique est con√ßu pour offrir √† tous l‚Äô√©tat d‚Äôesprit, les comp√©tences et les outils n√©cessaires pour percevoir l‚Äôintelligence artificielle d‚Äôun nouveau point de vue stimulant: ‚Äî Des d√©couvertes et des connaissances scientifiques de pointe;‚Äî Les meilleurs codes et impl√©mentations ‚Äúopen source‚Äù;‚Äî L‚Äôimpulsion qui anime l‚Äôintelligence artificielle d‚Äôaujourd‚Äôhui. Con√ßu pour les artistes, #AI4Artists est cr√©√© pour inspirer les artistes qui, avec IA, fa√ßonneront le 21√®me si√®cle. Une c√©l√©bration vraiment sp√©ciale qui marquera certainement l‚Äôhistoire!Pour Andr√© Breton, le p√®re du surr√©alisme, le but de l‚Äôart est l‚Äôunification du r√©el et de l‚Äôimaginaire. Les Beaux-Arts de Montr√©al.IA r√©alise le r√™ve de Breton. Une c√©l√©bration vraiment sp√©ciale dans le monde des beaux-arts, de la mode et de la haute-joaillerie et qui fera certainement l‚Äôhistoire! Nous recherchons des ambassadeurs et des partenaires. ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/beaux-arts/index.html"},{"title":"MONTR√âAL.IA | Intelligence artificielle Montr√©al","text":"√âV√âNEMENTS DE MONTR√âAL.IAD√Æner de presse | Concert | Vente aux ench√®res | Gala de bienfaisance ‚ùñ C√©l√©bration des chefs de file de l‚Äôindustrie de l‚ÄôIAHommage aux chefs de file prim√©s de l‚Äôindustrie de l‚ÄôIA &amp; des sommit√©s ‚ùñ D√Æner de presse de MONTR√âAL.IAHommage au journalisme en IA m√©ritant ‚ùñ Vente aux ench√®res des beaux-arts de MONTR√âAL.IAD√©voilement d‚Äôun monde de secrets cach√©s‚Ä¶ Le 25 octobre 2018, la premi√®re ≈ìuvre d‚Äôart en intelligence artificielle jamais vendue par la maison de ventes aux ench√®res Christie‚Äôs a boulevers√© les attentes, atteignant 432 500 $. Aujourd‚Äôhui, la Maison des Beaux-Arts de Montr√©al.IA pr√©sente : La vente aux ench√®res des Beaux-Arts de Montr√©al.IA, la premi√®re vente aux ench√®res internationale consacr√©e √† la quintessence des Beaux-Arts de l‚ÄôIA. ‚ÄúLes artistes qui cr√©ent avec AI ne suivront pas les tendances, ils les d√©finiront.‚Äú ‚Äî Montr√©al.IA Nous nous pr√©parons pour la premi√®re vente aux ench√®res. Les plus grands collectionneurs d‚Äô≈ìuvres d‚Äôart pourront faire des offres √† l‚Äô√©chelle internationale. ‚ùñ Salon de MONTR√âAL.IARassemblement de gens sous le toit d‚Äôun h√¥te inspirant ‚ùñ Conversation au coin du feu de MONTR√âAL.IA ‚ùñ Acad√©mie de MONTR√âAL.IA : IA 101Instituer une compr√©hension percutante de l‚ÄôIAIA 101 : Pour les novices en intelligence artificielle !Le mardi 26 novembre 2019 | 18h30 - 20h30, le Secr√©tariat g√©n√©ral de MONTR√âAL.IA pr√©sentera, avec savoir-faire : ‚ÄúArtificial Intelligence 101: The First World-Class Overview of AI for the General Public‚Äú (en anglais). Lieu : NRH Prince Arthur - Salle de bal, 3625, avenue du Parc, Montr√©al (Qu√©bec), Canada, H2X 3P8. Billets et r√©servation de groupeR√©servation de groupe : secretariat@montreal.ai Billets : https://ai101montreal.eventbrite.ca Langue : Conf√©rence en anglais.Date et heure : Mardi, 26 novembre 2019 | 18h30 - 20h30Lieu : NRH Prince Arthur - Salle de bal, 3625, avenue du Parc, Montr√©al (Qu√©bec), Canada, H2X 3P8. var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '68213946751', iframeContainerId: 'eventbrite-widget-container-68213946751', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); ‚Äú(L‚ÄôIA) comptera parmi nos plus grandes r√©alisations technologiques, et tout le monde m√©rite de jouer un r√¥le dans son √©laboration.‚Äú ‚Äî Fei-Fei Li ‚ùñ D√Æner des ambassadeurs de MONTR√âAL.IA ‚ùñ Orchestre de MONTR√âAL.IADes symphonies pionni√®res surhumaines var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '59763841258', iframeContainerId: 'eventbrite-widget-container-59763841258', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); ‚ùñ Gala du M√©rite philanthropique de MONTR√âAL.IA ‚ÄúC‚Äôest le printemps pour l‚ÄôIA, et nous pr√©voyons un long √©t√©.‚Äú ‚Äî Bill Braun, CIO de Chevron ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/evenements/index.html"}],"posts":[{"title":"MONTR√âAL.IA | Intelligence artificielle Montr√©al","text":"MONTR√âAL.IA | Intelligence artificielle Montr√©alPremier conglom√©rat de l‚Äôintelligence artificielle (IA) √† Montr√©al Moteur √©conomique du Grand Montr√©al en IAL‚ÄôIA est capable de profond√©ment transformer les industries.MONTR√âAL.IA | Intelligence Artificielle Montr√©al (constitution : mars 2003) est une entreprise de recherche √† la fine pointe de l‚ÄôIA qui d√©veloppe et commercialise la technologie la plus d√©terminante jamais invent√©e. Le Groupe de travail MONTR√âAL.IA op√®re de mani√®re unilat√©rale ou en association avec des partenaires internationaux et institutionnels. Apr√®s avoir cr√©√© la plus grande communaut√© d‚ÄôIA au Canada , le temps est venu de d√©ployer √† une √©chelle colossale la plus importante entreprise d‚ÄôIA √† Montr√©al : MONTR√âAL.IA. MONTR√âAL.IA vise le statut d‚Äôentreprise milliardaire ( Unicorn Status ). Technologies pr√©-AGISous la tutelle de MONTR√âAL.IA, plusieurs entreprises et organisations sont pr√©sentement structur√©es afin d‚Äôappliquer des technologies pr√©-AGI extr√™mement impactantes pour r√©gler des probl√®mes √† l‚Äô√©chelle plan√©taire. ‚ÄúUne strat√©gie commerciale r√©ussie consiste √† fa√ßonner activement le jeu auquel vous jouez, et pas seulement √† y jouer.‚Äú ‚Äî A. Brandenburger &amp; B. Nalebuff MONTR√âAL.IA mobilise les capitaines de l‚Äôindustrie, entrepreneurs iconiques en technologie, intellectuels, philanthropes, sp√©cialistes et financiers chevronn√©s dans cette t√¢che aux proportions historiques. ‚úâÔ∏è Courriel : info@montreal.aiüìû T√©l√©phone : +1.514.829.8269üåê Site web : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Secr√©tariat G√©n√©ral de Montr√©al.IA : 350, RUE PRINCE-ARTHUR OUEST, SUITE #2105, MONTR√âAL [QC], CANADA, H2X 3R4 *Conseil ex√©cutif et bureau administratif #IntelligenceArtificielle #IntelligenceArtificielleMontreal #MontrealIA","link":"/MontrealIA.github.io/2018/06/27/index/"}],"tags":[],"categories":[]}